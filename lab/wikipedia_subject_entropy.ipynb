{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分 Wikipedia 学科, 使用 core 学科"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import tqdm\n",
    "import collections\n",
    "\n",
    "env_config = dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = f\"wikipedia_dump_v{env_config['WIKI_VERSION']}\"\n",
    "wikipedia_collection = pymongo.MongoClient(env_config['Mongo_Url'])[database_name][\"revision_complete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到所有存在 page linksin 的 category\n",
    "\n",
    "# category_set = set()\n",
    "\n",
    "# for doc in tqdm.tqdm(wikipedia_collection.find({'page_category_links_out':{'$ne':None}},{'page_category_links_out':1})):\n",
    "#     category_set.update(doc['page_category_links_out'])\n",
    "\n",
    "# len(category_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到所有存在 page linksin 的 category\n",
    "\n",
    "# category_set = set(wikipedia_collection.distinct('page_category_links_out'))\n",
    "# len(category_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到匹配的条件的 category core name\n",
    "subject_list = [ \"Mathematics\", \"Physics\", \"Computer science\", \"Engineering disciplines\", \"Medicine\",\n",
    "\t\t\"Biology\", \"Chemistry\", \"Materials science\", \"Geology\", \"Geography\", \"Environmental science\",\n",
    "\t\t\"Economics\", \"Sociology\", \"Psychology\", \"Political science\", \"Philosophy\", \"Business\", \"Art\",\n",
    "\t\t\"History\" ]\n",
    "\n",
    "core_key_1 = [\"Subfields of\", \"Areas of\" \"Fields of\", \"Branches of\", \"Subdivisions of\"]\n",
    "\n",
    "core_key_2 = [\"by field\", \"by fields\", \"of field\", \"by specialty\"]\n",
    "\n",
    "subject_key_map = collections.defaultdict(set)\n",
    "total_map = set()\n",
    "\n",
    "for name in subject_list:\n",
    "    subject_key_map[name] = set()\n",
    "    low_name = name.lower()\n",
    "    for key in core_key_2:\n",
    "        subject_key_map[name].add(f\"{low_name} {key.lower()}\")\n",
    "        total_map.add(f\"{low_name} {key.lower()}\")\n",
    "    for key in core_key_1:\n",
    "        subject_key_map[name].add(f\"{key.lower()} {low_name}\")\n",
    "        total_map.add(f\"{key.lower()} {low_name}\")\n",
    "    \n",
    "    total_map.add(low_name)\n",
    "        \n",
    "# subject_key_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2526905/2526905 [00:01<00:00, 1454956.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# # 生成子学科到主学科的映射, 子学科区分大小写\n",
    "\n",
    "# # core cat\n",
    "# subject_core_cat_map = collections.defaultdict(set)\n",
    "\n",
    "# # 包含主学科的 cat set\n",
    "# subject_chief_cat_map = collections.defaultdict(set)\n",
    "\n",
    "# for cat_name in tqdm.tqdm(category_set):\n",
    "#     cat_name_lower = cat_name.lower()\n",
    "#     if cat_name_lower in total_map:\n",
    "#         for subject_name , cat_set in subject_key_map.items():\n",
    "#             if cat_name_lower in cat_set:\n",
    "#                 subject_core_cat_map[subject_name].add(cat_name)\n",
    "#             elif cat_name_lower == subject_name.lower():\n",
    "#                 subject_chief_cat_map[subject_name].add(cat_name)\n",
    "     \n",
    "# reverse_subject_core_cat_map = {}\n",
    "# for name, items in subject_core_cat_map.items():\n",
    "#     for sub_name in items:\n",
    "#         reverse_subject_core_cat_map[sub_name] = name\n",
    "        \n",
    "# reverse_subject_chief_cat_map = {}\n",
    "# for name, items in subject_chief_cat_map.items():\n",
    "#     for sub_name in items:\n",
    "#         reverse_subject_chief_cat_map[sub_name] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engineering disciplines', 'Engineering disciplines'}\n",
      "{'Medicine', 'medicine'}\n",
      "{'Materials science', 'Materials Science', 'materials science'}\n",
      "{'Environmental science', 'Environmental Science'}\n",
      "{'Business', 'business'}\n",
      "{'Art'}\n"
     ]
    }
   ],
   "source": [
    "# # reverse_subject_chief_cat_map\n",
    "\n",
    "# # subject_core_cat_map\n",
    "# # subject_chief_cat_map\n",
    "\n",
    "# for name in subject_list:\n",
    "#     if name not in subject_core_cat_map:\n",
    "#         print(subject_chief_cat_map[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# 逻辑处理\n",
    "要计算的学科子图\n",
    "\n",
    "1. 一层 core subject category page (有多个都用一层), 无 core subject category 的就用一层 subject category page\n",
    "2. 扩展到二层, 三层, 每年独立计算 category 层级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007 262895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262895/262895 [00:00<00:00, 1433113.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_category_range(year:int):\n",
    "    \n",
    "    # 找到当前所有的 category linksin\n",
    "    category_set = set()\n",
    "    for doc in wikipedia_collection.find({'ns':0,'year_tags':year, 'page_category_links_out':{'$ne':None}},{'page_category_links_out':1}):\n",
    "        category_set.update(doc['page_category_links_out'])\n",
    "    print(year, len(category_set))\n",
    "    \n",
    "    # 生成子学科到主学科的映射, 子学科区分大小写\n",
    "\n",
    "    # core cat\n",
    "    subject_core_cat_map = collections.defaultdict(set)\n",
    "\n",
    "    # 包含主学科的 cat set\n",
    "    subject_chief_cat_map = collections.defaultdict(set)\n",
    "\n",
    "    for cat_name in tqdm.tqdm(category_set):\n",
    "        cat_name_lower = cat_name.lower()\n",
    "        if cat_name_lower in total_map:\n",
    "            for subject_name , cat_set in subject_key_map.items():\n",
    "                if cat_name_lower in cat_set:\n",
    "                    subject_core_cat_map[subject_name].add(cat_name)\n",
    "                elif cat_name_lower == subject_name.lower():\n",
    "                    subject_chief_cat_map[subject_name].add(cat_name)\n",
    "                    \n",
    "    # 对没有 core cat 的学科进行补充\n",
    "    for name in subject_list:\n",
    "        if name not in subject_core_cat_map:\n",
    "            for item in subject_chief_cat_map[name]:\n",
    "                subject_core_cat_map[name].add(item)\n",
    "    \n",
    "    # 生成反向 map\n",
    "    reverse_subject_core_cat_map = {}\n",
    "    for name, items in subject_core_cat_map.items():\n",
    "        for sub_name in items:\n",
    "            reverse_subject_core_cat_map[sub_name] = name\n",
    "            \n",
    "    # 获取了当年的所有主学科和子学科的映射\n",
    "    lv1_subject_dict = collections.defaultdict(set)\n",
    "    lv2_subject_dict = collections.defaultdict(set)\n",
    "    lv3_subject_dict = collections.defaultdict(set)\n",
    "    \n",
    "    # lv2\n",
    "    for cat_name, subject_name in reverse_subject_core_cat_map.items():\n",
    "        for doc in wikipedia_collection.find({'ns':14,'year_tags':year, 'page_category_links_out': cat_name}):\n",
    "            sub_cat_name = doc['title'].split(\":\")[-1]\n",
    "            lv2_subject_dict[subject_name].add(sub_cat_name)\n",
    "            \n",
    "    # lv3\n",
    "    for subject_name, cat_name_list in lv2_subject_dict.items():\n",
    "        for cat_name in cat_name_list:\n",
    "            # lv3 包含lv2\n",
    "            lv3_subject_dict[subject_name].add(cat_name)\n",
    "            for doc in wikipedia_collection.find({'ns':14,'year_tags':year, 'page_category_links_out': cat_name}):\n",
    "                sub_cat_name = doc['title'].split(\":\")[-1]\n",
    "                lv3_subject_dict[subject_name].add(sub_cat_name)\n",
    "    \n",
    "    # lv1 \n",
    "    for cat_name, subject_name in reverse_subject_core_cat_map.items():\n",
    "        lv1_subject_dict[subject_name].add(cat_name)\n",
    "        # lv2, lv3 包含 lv1\n",
    "        lv2_subject_dict[subject_name].add(cat_name)\n",
    "        lv3_subject_dict[subject_name].add(cat_name)\n",
    "    \n",
    "    return lv1_subject_dict, lv2_subject_dict, lv3_subject_dict\n",
    "\n",
    "\n",
    "wikipedia_collection.create_index([('core_subject_tag', pymongo.ASCENDING)],background=True,sparse=True)\n",
    "\n",
    "def calculate_yearly_subject_entropy(year:int):\n",
    "    \n",
    "    lv1_subject_dict, lv2_subject_dict, lv3_subject_dict = get_category_range(year)\n",
    "    \n",
    "    core_tag_map = collections.defaultdict(set)\n",
    "    \n",
    "    for subject_name, cat_name_list in lv1_subject_dict.items():\n",
    "        for cat_name in cat_name_list:\n",
    "            for doc in wikipedia_collection.find({'ns':0, 'page_category_links_out':cat_name, 'year_tags':year},{'_id':1}):\n",
    "                core_tag_map[doc['_id']].add(f\"lv1-{subject_name}-{year}\")\n",
    "                \n",
    "    for subject_name, cat_name_list in lv2_subject_dict.items():\n",
    "        for cat_name in cat_name_list:\n",
    "            for doc in wikipedia_collection.find({'ns':0, 'page_category_links_out':cat_name, 'year_tags':year},{'_id':1}):\n",
    "                core_tag_map[doc['_id']].add(f\"lv2-{subject_name}-{year}\")\n",
    "                \n",
    "    for subject_name, cat_name_list in lv3_subject_dict.items():\n",
    "        for cat_name in cat_name_list:\n",
    "            for doc in wikipedia_collection.find({'ns':0, 'page_category_links_out':cat_name, 'year_tags':year},{'_id':1}):\n",
    "                core_tag_map[doc['_id']].add(f\"lv3-{subject_name}-{year}\")\n",
    "          \n",
    "    bulk_operate_list = []      \n",
    "    for doc_id, tag_set in core_tag_map.items():\n",
    "        bulk_operate_list.append(\n",
    "            pymongo.UpdateOne(\n",
    "                {'_id':doc_id},\n",
    "                {'$addToSet':{'core_subject_tag':{\"$each\":list(tag_set)}}}\n",
    "            )\n",
    "        )\n",
    "    wikipedia_collection.bulk_write(bulk_operate_list)\n",
    "    print('bulk_operate_list', len(bulk_operate_list))\n",
    "                \n",
    "lv1_subject_dict, lv2_subject_dict, lv3_subject_dict = get_category_range(2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Psychology',\n",
       " 'Sociology',\n",
       " 'Geography',\n",
       " 'Philosophy',\n",
       " 'Political science',\n",
       " 'Mathematics',\n",
       " 'Physics',\n",
       " 'Computer science',\n",
       " 'Engineering disciplines',\n",
       " 'Medicine',\n",
       " 'Biology',\n",
       " 'Chemistry',\n",
       " 'Materials science',\n",
       " 'Geology',\n",
       " 'Environmental science',\n",
       " 'Economics',\n",
       " 'Business',\n",
       " 'History']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lv3_subject_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 100626.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004 36037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36037/36037 [00:00<00:00, 1381413.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 22602\n",
      "2005 85012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85012/85012 [00:00<00:00, 1383557.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 47367\n",
      "2006 171153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171153/171153 [00:00<00:00, 1389783.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 60992\n",
      "2007 262895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262895/262895 [00:00<00:00, 1437512.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 78648\n",
      "2008 348682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348682/348682 [00:00<00:00, 1489525.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 101955\n",
      "2009 427088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427088/427088 [00:00<00:00, 1478030.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 112129\n",
      "2010 517027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517027/517027 [00:00<00:00, 1446003.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 120845\n",
      "2011 623140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623140/623140 [00:00<00:00, 1485604.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 113086\n",
      "2012 711986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 711986/711986 [00:00<00:00, 1509993.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 124422\n",
      "2013 813709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 813709/813709 [00:00<00:00, 1486004.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 120953\n",
      "2014 896642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 896642/896642 [00:00<00:00, 1524352.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 123072\n",
      "2015 992983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 992983/992983 [00:00<00:00, 1504034.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 131418\n",
      "2016 1085536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1085536/1085536 [00:00<00:00, 1489285.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 125021\n",
      "2017 1174384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1174384/1174384 [00:00<00:00, 1489252.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 124077\n",
      "2018 1250712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250712/1250712 [00:00<00:00, 1458577.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 125717\n",
      "2019 1326529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1326529/1326529 [00:00<00:00, 1499622.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 131838\n",
      "2020 1415147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1415147/1415147 [00:00<00:00, 1461572.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 150929\n",
      "2021 1492281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492281/1492281 [00:01<00:00, 1481158.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 154574\n",
      "2022 1562671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562671/1562671 [00:01<00:00, 1490592.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 152393\n",
      "2023 1638406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1638406/1638406 [00:01<00:00, 1463403.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 144258\n",
      "2024 1715068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1715068/1715068 [00:01<00:00, 1479130.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_operate_list 148805\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(600)\n",
    "\n",
    "# 测试成功\n",
    "for year in range(2003,2024+1):\n",
    "    calculate_yearly_subject_entropy(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
